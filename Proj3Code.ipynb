{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Image Features Using PCA\n",
    "\n",
    "A variety of applications, including face recognition, computer vision, and medical imaging, are based on performing computations on image data. These image data are high-dimensional, which it makes it difficult to store large volumes of images as well as extract patterns from images. A key step in image processing algorithms is to identify low-dimensional features, which can then be used to process, manipulate, and compress/store the images. Principal component analysis is an important tool for doing so.\n",
    "\n",
    "Analysis of images is a special case of PCA. Let $x_{1},\\ldots,x_{N}$ denote a set of images, where $x_{i} \\in \\mathbb{R}^{M}$ and $M$ is the total number of pixels in each image. The data matrix $X$ is an $M \\times N$ matrix in which the columns are $x_{1},\\ldots,x_{N}$. By taking the SVD of $X$ and performing PCA, we can identify the principal components of the images, which we can then use to compress and classify them.\n",
    "\n",
    "In this project, you will work with the Extended Yale B dataset (unpadded), which is also known as the Eigenfaces dataset \\cite{gross2005face}. The dataset consists of images of the faces of 15 people. There are multiple images for each person, representing different facial expressions and lighting conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 \n",
    "Download the image dataset. Load all of the images for the first 13 subjects. Your training dataset will consist of these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Loading the data\n",
    "import os\n",
    "suffixes = ['centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', \n",
    "            'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink']\n",
    "\n",
    "num_faces_training = 13\n",
    "num_suffixes = len(suffixes)\n",
    "num_imgs_total = num_faces_training * num_suffixes\n",
    "\n",
    "img_height = 116\n",
    "img_width = 98\n",
    "img_size = img_height * img_width\n",
    "\n",
    "img_matrix = np.zeros((img_size, num_imgs_total))\n",
    "\n",
    "# *************************\n",
    "# Implement your code here\n",
    "# \n",
    "# *************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the total number of images matches the expected number\n",
    "if img_matrix.shape == (img_size, num_imgs_total):\n",
    "    print(\"Part 1: Pass - Data loaded successfully with correct dimensions.\")\n",
    "else:\n",
    "    print(\"Part 1: Fail - Data dimensions or loading process may have issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Generate X matrix\n",
    "Generate the data matrix $X$ for the images in your training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************\n",
    "# Implement your code here\n",
    "# \n",
    "# feature_mean = \n",
    "# X =\n",
    "# *************************\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(feature_mean.reshape(img_height, img_width), cmap='gray')\n",
    "plt.title(\"Mean Image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the mean of the columns in X is close to zero\n",
    "if np.allclose(np.mean(X, axis=1), 0, atol=1e-6):\n",
    "    print(\"Part 2: Pass - Data matrix X is correctly mean-centered.\")\n",
    "else:\n",
    "    print(\"Part 2: Fail - Data matrix X is not mean-centered properly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Compute SVD\n",
    "Compute the SVD of $X$. Plot the singular values. How many principal components are needed to capture $70\\%$ of the training image data? $80\\%$? $90\\%$? $95\\%$? By what factor can we reduce the storage required to store each image if we only need to recover $90\\%$ of the data in the image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************\n",
    "# Implement your code here\n",
    "# \n",
    "# *************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of U, s, and Vh\n",
    "if U.shape == (img_size, num_imgs_total) and s.shape == (num_imgs_total,) and Vh.shape == (num_imgs_total, num_imgs_total):\n",
    "    print(\"Part 3: Pass - SVD computation completed with correct matrix dimensions.\")\n",
    "else:\n",
    "    print(\"Part 3: Fail - SVD matrix dimensions do not match expectations.\")\n",
    "\n",
    "# Check if the cumulative variance sums to 1 (within numerical tolerance)\n",
    "singular_values_squared = s ** 2\n",
    "total_variance = np.sum(singular_values_squared)\n",
    "cumulative_variance = np.cumsum(singular_values_squared) / total_variance\n",
    "\n",
    "# Check if the cumulative variance sums to 1 within a numerical tolerance\n",
    "if np.isclose(cumulative_variance[-1], 1.0, atol=1e-6):\n",
    "    print(\"Part 3: Pass - Cumulative variance is correctly computed.\")\n",
    "else:\n",
    "    print(\"Part 3: Fail - Cumulative variance computation may have issues.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Approximation error calculations\n",
    "Suppose that we represent each image using the first $d=20$ features identified with PCA. What is the average approximation error of this representation? Repeat this step with $d=50,70,100$. Pick one of the training images and plot the original image along with the reconstruction for each value of $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************\n",
    "# Implement your code here\n",
    "# \n",
    "# *************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in d_values:\n",
    "    U_d = U[:, :d]  # Select the first d columns of U\n",
    "    S_d = np.diag(s[:d])  # Create a diagonal matrix of the first d singular values\n",
    "    Vh_d = Vh[:d, :]  # Select the first d rows of Vh\n",
    "\n",
    "    # Approximate the data matrix using the top d components\n",
    "    X_approx = U_d @ S_d @ Vh_d\n",
    "\n",
    "    # Compute the average approximation error\n",
    "    error = np.linalg.norm(X - X_approx, 'fro') ** 2\n",
    "    average_approximation_error.append(error / num_imgs_total)\n",
    "\n",
    "    # Reconstruction for a sample image (e.g., first image)\n",
    "    sample_image_index = 0\n",
    "    reconstructed_image = X_approx[:, sample_image_index].reshape(img_height, img_width)\n",
    "\n",
    "    # Plot the original and reconstructed images\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_matrix[:, sample_image_index].reshape(img_height, img_width), cmap='gray')\n",
    "    plt.title('Original Image')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(reconstructed_image, cmap='gray')\n",
    "    plt.title(f'Reconstructed Image (d={d})')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************\n",
    "# Implement your code here\n",
    "# \n",
    "# *************************\n",
    "\n",
    "print(\"Updated average approximation errors for each d:\", average_approximation_error)\n",
    "tolerance = 1e-5\n",
    "if all(earlier >= later - tolerance for earlier, later in zip(average_approximation_error, average_approximation_error[1:])):\n",
    "    print(\"Part 4: Pass - Approximation error decreases as d increases (within tolerance).\")\n",
    "else:\n",
    "    print(\"Part 4: Fail - Approximation error does not decrease as expected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Reconstruct images\n",
    "Load the images from the remaining two subjects. Using the first 50 features from the training dataset, compute the feature values for all of the images in the test dataset. What is the approximation error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************\n",
    "# Implement your code here\n",
    "# \n",
    "# *************************\n",
    "\n",
    "# Calculate the average approximation error for the test set\n",
    "average_approximation_error_test_set = np.mean(approximation_errors)\n",
    "print(f\"Average approximation error for the test set with d={d}: {average_approximation_error_test_set}\")\n",
    "\n",
    "# Visualize a sample reconstructed image\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_img_matrix[:, 0].reshape(img_height, img_width), cmap='gray')\n",
    "plt.title('Original Test Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(reconstructed_image.reshape(img_height, img_width), cmap='gray')\n",
    "plt.title(f'Reconstructed Image (d={d})')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Reconstruct rotated image\n",
    "Repeat the previous step using the rotated image `subject15rotated.jpeg'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_img_data = imageio.imread('subject15rotated.jpeg')\n",
    "# *************************\n",
    "# Implement your code here\n",
    "# \n",
    "# *************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(rotated_img_data.reshape(img_height, img_width), cmap='gray')\n",
    "plt.title('Original Rotated Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow((img_vector - feature_mean).reshape(img_height, img_width), cmap='gray')\n",
    "plt.title(f'Reconstructed Rotated Image (d={d})')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
